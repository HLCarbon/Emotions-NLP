{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from autocorrect import Speller\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First things first, let's look a little bit at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.txt', sep = ';',header = None )\n",
    "test.head()\n",
    "train = pd.read_csv('train.txt', sep = ';',header = None )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         695\n",
       "sadness     581\n",
       "anger       275\n",
       "fear        224\n",
       "love        159\n",
       "surprise     66\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is already separated into a test file and a training file so we don't need to do a train test split. As we can see the data isn't really made equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns = {1:'labels', 0:'sentences'}, inplace = True)\n",
    "test.rename(columns = {1:'labels', 0:'sentences'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "- Remove characters that are not letters\n",
    "- apply .lower() to every word\n",
    "- tokenization\n",
    "- remove the stop words\n",
    "- stemming \n",
    "- Correct the spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing non common characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sentences = train.sentences.apply(lambda x: re.sub('[^A-Za-z]',' ', x))\n",
    "test.sentences = test.sentences.apply(lambda x: re.sub('[^A-Za-z]',' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply .lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sentences = train.sentences.str.lower()\n",
    "test.sentences = test.sentences.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sentences = train.sentences.apply(lambda x: word_tokenize(x))\n",
    "test.sentences = test.sentences.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stop words, correct spelling and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_correcter = Speller()\n",
    "stemmer  = PorterStemmer()\n",
    "\n",
    "def remover_correct_stemm(message_columns: pd.Series):\n",
    "    list_of_emails = []\n",
    "    for row in tqdm(message_columns):\n",
    "        lst = []\n",
    "        for word in row:\n",
    "            #remove the words that are stopwords\n",
    "            if word not in stopwords.words('english'):\n",
    "                #corrects the spelling\n",
    "                corrected_word = spell_correcter(word)\n",
    "                #stems each word\n",
    "                word_stemm = stemmer.stem(corrected_word)\n",
    "                #makes a new sentence without the stop words, with the word stemmed and without spelling errors\n",
    "                lst.append(word_stemm)\n",
    "        #appends to the big list\n",
    "        lst = ' '.join(lst)\n",
    "        list_of_emails.append(lst)\n",
    "    return list_of_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16000/16000 [16:26<00:00, 16.23it/s] \n",
      "100%|██████████| 2000/2000 [01:23<00:00, 23.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train.sentences =remover_correct_stemm(train.sentences)\n",
    "test.sentences =remover_correct_stemm(test.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        didnt feel humili\n",
       "1        go feel hopeless damn hope around someon care ...\n",
       "2                     im grab minut post feel greedi wrong\n",
       "3           ever feel nostalg fireplac know still properti\n",
       "4                                             feel grouchi\n",
       "                               ...                        \n",
       "15995        brief time beanbag said anna feel like beaten\n",
       "15996     turn feel pathet still wait tabl dub teach degre\n",
       "15997                              feel strong good overal\n",
       "15998                       feel like rude comment im glad\n",
       "15999                         know lot feel stupid portray\n",
       "Name: sentences, Length: 16000, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "counter = CountVectorizer()\n",
    "x_train = counter.fit_transform(train.sentences).toarray()\n",
    "x_test = counter.transform(test.sentences).toarray()\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.84      0.66      0.74       275\n",
      "        fear       0.79      0.59      0.68       224\n",
      "         joy       0.76      0.93      0.84       695\n",
      "        love       0.74      0.33      0.45       159\n",
      "     sadness       0.75      0.89      0.82       581\n",
      "    surprise       0.80      0.06      0.11        66\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.78      0.58      0.61      2000\n",
      "weighted avg       0.77      0.77      0.75      2000\n",
      "\n",
      "Accuracy:\n",
      " 0.768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(test['labels'], model.predict(x_test)))\n",
    "print('Accuracy:\\n', accuracy_score(test['labels'], model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37134ace218921b74af13dd92c56fdadfb15c5b94d65c3fac1e4c7a849f19ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
